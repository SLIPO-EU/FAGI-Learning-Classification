{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification for POIs fusion validation action -  Double data case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from sklearn import svm \n",
    "from sklearn.model_selection import train_test_split, cross_validate, ShuffleSplit, KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = pd.read_csv(\"features_export.csv\") # must be on the same folder\n",
    "X1 = feat[feat.columns.values[range(feat.shape[1]-2)]]\n",
    "test=pd.DataFrame()\n",
    "X1 = transform2(X1,test)\n",
    "X11, X22 = transform_object_pair(test, ' BcontainsFT_T', ' AcontainsFT_T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification process\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", #\"QDA\", \n",
    "         \"DecisionTreeClassifier\",\"GradientBoostingClassifier\",\n",
    "         \"ExtraTreesClassifier\",\"ExtraTreesClassifier\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    svm.SVC(kernel=\"linear\", C=0.025),\n",
    "    svm.SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1,max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    #QuadraticDiscriminantAnalysis(),\n",
    "    DecisionTreeClassifier(max_depth=None, min_samples_split=2, random_state=0),\n",
    "    GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0),\n",
    "    ExtraTreesClassifier(n_estimators=28, max_depth=None, min_samples_split=11, random_state=0),\n",
    "    ExtraTreesClassifier(n_estimators=24, max_depth=None, min_samples_split=3, random_state=0),\n",
    "    ]\n",
    "\n",
    "cross={}  \n",
    "# Read the data\n",
    "\n",
    "feat = pd.read_csv(\"features_export.csv\")\n",
    "X1 = feat[feat.columns.values[range(40)]]\n",
    "X1 = transform2(X1,test)\n",
    "kf = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "k=0\n",
    "for train_index, test_index in kf.split(X1):\n",
    "   \n",
    "    \n",
    "    # split the data\n",
    "    X_train, X_test = X1.iloc[train_index], X1.iloc[test_index]\n",
    "    z= X1[' acceptance']\n",
    "    y_train, y_test = z[train_index], z[test_index]\n",
    "\n",
    "    X2 =swap_symetric(X_train)\n",
    "    \n",
    "    \n",
    "    X_train = pd.concat([X_train, X11.iloc[train_index], X22.iloc[train_index]], axis=1)# append the expanded object\n",
    "    X2 = pd.concat([X2, X22.iloc[train_index], X11.iloc[train_index]], axis=1)# append the expanded object\n",
    "    \n",
    "    X = pd.concat([X_train, X2], axis=0)  \n",
    "    y = X.pop(' acceptance')\n",
    "\n",
    "    X_test = pd.concat([X_test, X11.loc[X_test.index], X22.loc[X_test.index]], axis=1)\n",
    "    X_test.pop(' acceptance');\n",
    "\n",
    "    for name, clf in zip(names, classifiers):\n",
    "\n",
    "        clf.fit(X,y)\n",
    "        if k==0:\n",
    "            cross[name]={'accuracy':[clf.score(X_test, y_test)]}\n",
    "        else:\n",
    "            zz=cross[name].get('accuracy')\n",
    "            zz.append(clf.score(X_test, y_test))\n",
    "            cross[name]={'accuracy':zz}\n",
    "    k=k+1\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf = {}\n",
    "scr = {}\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "for name, clf in zip(names, classifiers):\n",
    "        #clf.fit(X_train, y_train)\n",
    "        scoring=['accuracy','precision','f1', 'recall']\n",
    "        scores = cross_validate(clf, X, y, cv=cv, scoring=scoring, return_train_score=True) # this function does cross validation\n",
    "\n",
    "        inf[name]= clf.get_params()\n",
    "        scr[name]={'test_score':scores.get('test_accuracy'),\n",
    "                   'train_score':scores.get('train_accuracy')}\n",
    "        clf.fit(X,y)\n",
    "        clf.score(X_test, y_test)\n",
    "\n",
    "        print(name, \":\" ,\"Test Accuracy: %0.2f (+/- %0.2f), Train Accuracy: %0.2f (+/- %0.2f)\" % (scores.get('test_accuracy').mean(), scores.get('test_accuracy').std() * 2,\n",
    "                                                                                                  scores.get('train_accuracy').mean(), scores.get('train_accuracy').std() * 2)) # print the average and variance of cv\n",
    "        print(name, \":\" ,\"Real Accuracy: \\033[91m %0.2f  (+/- %0.2f)\\033[0m\" % (np.asarray(cross[name].get('accuracy')).mean(), np.asarray(cross[name].get('accuracy')).std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}\n",
    "gs = GridSearchCV(ExtraTreesClassifier( random_state=0),\n",
    "                  param_grid={'n_estimators': range(15,30), 'min_samples_split': range(2, 35)},\n",
    "                 scoring=scoring, cv=5, refit='AUC',n_jobs=4)\n",
    "gs.fit(X, y)\n",
    "results = gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
